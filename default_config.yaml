# Configuration file for Dance Movement Analysis System
# Based on the paper: Deep Learning Framework for Aesthetic and Biomechanical Optimization of Dance Movements

# Experiment settings
experiment_name: "dance_aesthetic_optimization_v1"
seed: 42
use_wandb: true
wandb_project: "dance-ai"
use_mlflow: true
mlflow_experiment: "dance-analysis"
use_tensorboard: true

# Data settings
data_root: "/path/to/dance/dataset"
sequence_length: 150  # 5 seconds at 30 fps
frame_size: [224, 224]
use_motion_capture: true
use_pose_estimation: true
cache_preprocessed: true
num_workers: 4

# Dance styles to include
dance_styles:
  - ballet
  - hip_hop
  - indian_classical
  - contemporary

# Model architecture
model:
  spatial_feature_dim: 512
  temporal_hidden_dim: 256
  num_lstm_layers: 2
  dropout: 0.3
  num_aesthetic_classes: 10
  enable_cam: true
  
  # CNN backbone
  backbone: "resnet50"
  pretrained: true
  
  # LSTM settings
  bidirectional: true
  attention_heads: 8
  
  # Feature fusion
  fusion_method: "gated"
  
# Training settings
training:
  batch_size: 32
  max_epochs: 50
  early_stopping_patience: 5
  
  # Optimizer
  optimizer: "adam"  # adam, adamw, sgd
  learning_rate: 0.001
  weight_decay: 0.0001
  
  # Learning rate scheduler
  scheduler: "step"  # step, cosine, plateau
  lr_step_size: 20
  lr_gamma: 0.1
  
  # Loss weights (from paper Equation 12)
  loss_weight_aesthetic: 1.0
  loss_weight_biomech: 0.5
  loss_weight_joint: 0.3
  
  # Mixed precision
  use_amp: true
  
  # Gradient clipping
  max_grad_norm: 1.0
  
  # Multi-GPU
  use_multi_gpu: true
  
  # Logging
  log_frequency: 10
  vis_frequency: 100
  
  # Checkpointing
  checkpoint_dir: "./checkpoints"
  save_frequency: 1
  pretrained_checkpoint: null  # Path to pretrained model if available

# Reinforcement Learning settings (Algorithm 2 from paper)
reinforcement_learning:
  use_reinforcement_learning: true
  
  # Environment settings (Algorithm 1)
  rl_max_steps: 100
  rl_w1: 0.6  # Aesthetic weight
  rl_w2: 0.3  # Biomechanical weight  
  rl_w3: 0.1  # Smoothness penalty weight
  
  # PPO settings
  rl_hidden_dim: 256
  rl_lr_actor: 0.0003
  rl_lr_critic: 0.0003
  rl_gamma: 0.99  # Discount factor
  rl_gae_lambda: 0.95  # GAE lambda
  rl_epsilon: 0.2  # PPO clip parameter
  rl_c1: 0.5  # Value loss coefficient
  rl_c2: 0.01  # Entropy coefficient
  rl_max_grad_norm: 0.5
  
  # Training settings
  rl_update_frequency: 100
  rl_buffer_size: 2048
  rl_n_rollouts: 10
  rl_n_epochs: 10
  rl_batch_size: 64

# Few-shot learning settings (Section 3.3 and 5.5)
few_shot_learning:
  enable: true
  method: "prototypical"  # maml, prototypical, relation
  
  # Task settings
  n_way: 5  # Number of classes per task
  k_shot: 5  # Number of examples per class in support set
  q_queries: 15  # Number of examples per class in query set
  
  # Meta-learning
  meta_lr: 0.001
  inner_lr: 0.01  # For MAML
  n_inner_steps: 5
  n_meta_epochs: 100
  n_tasks_per_epoch: 100
  
  # Adaptation
  n_adaptation_steps: 10
  adaptation_lr: 0.01

# Data augmentation settings
augmentation:
  train:
    random_rotate90: 0.5
    flip: 0.5
    shift_scale_rotate:
      shift_limit: 0.1
      scale_limit: 0.1
      rotate_limit: 15
      p: 0.5
    brightness_contrast:
      brightness_limit: 0.2
      contrast_limit: 0.2
      p: 0.5
    gauss_noise:
      var_limit: [10.0, 50.0]
      p: 0.3
    elastic_transform:
      alpha: 120
      sigma: 6
      p: 0.3
    optical_distortion: 0.3
    coarse_dropout:
      max_holes: 8
      max_height_ratio: 0.1
      max_width_ratio: 0.1
      p: 0.3
    
  # Temporal augmentation
  temporal:
    random_crop: true
    speed_augmentation:
      min_speed: 0.8
      max_speed: 1.2
      p: 0.5

# Evaluation settings
evaluation:
  calculate_inter_rater: true
  metrics:
    - mse
    - rmse
    - mae
    - pearson_correlation
    - spearman_correlation
    - fleiss_kappa
    
  # Biomechanical evaluation
  biomechanical:
    joint_stress_threshold: 0.7
    safe_angle_deviation: 0.2
    
  # Aesthetic evaluation thresholds
  aesthetic:
    fluidity_weight: 0.3
    expressiveness_weight: 0.4
    precision_weight: 0.3

# Inference settings
inference:
  batch_size: 16
  use_tta: true  # Test-time augmentation
  n_tta_samples: 5
  
# Visualization settings
visualization:
  cam_colormap: "jet"
  cam_alpha: 0.5
  save_visualizations: true
  visualization_dir: "./visualizations"
  
  # Video generation
  generate_optimized_videos: true
  video_fps: 30
  video_codec: "mp4v"

# Hardware settings
hardware:
  gpu_ids: [0, 1, 2, 3]  # For multi-GPU training
  num_threads: 8
  
  # Memory optimization
  gradient_checkpointing: false
  accumulate_grad_batches: 1

# Deployment settings
deployment:
  model_format: "onnx"  # onnx, torchscript, tflite
  quantization:
    enable: false
    method: "dynamic"  # dynamic, static, qat
    backend: "qnnpack"
  
  # API settings
  api:
    host: "0.0.0.0"
    port: 8000
    workers: 4
    timeout: 60
    max_batch_size: 32

# Dataset paths for different dance styles
datasets:
  ballet:
    train: "data/ballet/train"
    val: "data/ballet/val"
    test: "data/ballet/test"
    
  hip_hop:
    train: "data/hip_hop/train"
    val: "data/hip_hop/val" 
    test: "data/hip_hop/test"
    
  indian_classical:
    train: "data/indian_classical/train"
    val: "data/indian_classical/val"
    test: "data/indian_classical/test"
    
  contemporary:
    train: "data/contemporary/train"
    val: "data/contemporary/val"
    test: "data/contemporary/test"

# Logging
logging:
  level: "INFO"
  log_dir: "./logs"
  save_logs: true
  
# Monitoring
monitoring:
  use_prometheus: false
  prometheus_port: 9090
  use_grafana: false
  grafana_port: 3000
